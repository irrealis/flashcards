defaults:
  deckName: Staging
  modelName: BasicMathJax
  tags:
  - Code
  - Algorithms
  - Books
  - AFI-AlgorithmsForInterviews
  - AFI-08-DesignProblems

  fields:
    Back: "**To-do: Back.**"

  markdownTabLength: 4


notes:

- fields:
    Front: |
      ## 08.01: Mosaic

      One popular form of computer art is photomosaics where you are given a collection of images called "tiles". Then, given a target image, you want to build another image which closely approximates the target image but is actually built by juxtaposing the tiles. Here the quality of approximation is mostly defined by human perception. It is often the case that with a given set of tiles, a user may want to build several mosaics.

      How would you design a software that produces high-quality mosaics with minimal compute time?

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 67.


- fields:
    Front: |
      ## 08.02: Search engine

      Modern keyword-based search engines maintain a collection of several billion documents. One of the key computations performed by a search engine is to retrieve all the documents that contain the keywords contained in a given query. This is a nontrivial task because it must be done within few tens of milliseconds.

      In this problem, we consider a smaller version of the problem where the collection of documents can fit within the RAM of a single computer.

      Given a million documents with an average size of ten kilobytes, design a program that can efficiently return the subset of documents containing a given set of words.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 68.


- fields:
    Front: |
      ## 08.03: IP forwarding

      There are many applications where instead of an exact match of strings, we are looking for a prefix match, i.e., given a set of strings and a search string, we want to find a string from the set that is a prefix of the search string. One application of this is Internet Protocol (IP) route lookup problem. When an IP packet arrives at a router, the router looks up the next hop for the packet by searching the destination IP address of the packet in its routing table. The routing table is specified as a set of prefixes on the IP address, and the router is supposed to identify the longest matching prefix. If this task is to be performed only once, it is impossible to do better than testing each prefix. However, an Internet core router needs to lookup millions of destination addresses on the set of prefixes every second. Hence it can be advantageous to do some precomputation.

      You are given a large set of strings \\(S\\) in advance. Given a query string \\(Q\\), how would you design a system that can identify the longest string \\(p \in S\\) that is a prefix of \\(Q\\)?

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 68.


- fields:
    Front: |
      ## 08.04: Spell checker

      Edit distance may not be the right distance function when performing spelling correction --- it does not take into account the commonly misspelled words or the proximity of letters on a keyboard.

      How would you build a spelling correction system?

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 68.


- fields:
    Front: |
      ## 08.05: Stemming

      When a user submits the query "computation" to a search engine, it is quite possible he might also be interested in documents containing the words "computers", "compute", and "computing". If you have several keywords in a query, it becomes difficult to search for all combinations of all variants of the words in the query.

      One way to solve this problem is to reduce all variants of a given word to one common root, both in the query string and in the documents. This process is called stemming. An example of stemming would be \\(\\{computers,computer,compute\\}\mapsto comput\\). It is almost impossible to succinctly capture all possible variants of all words in the English language, but a few simple rules can get us a majority of the cases.

      Design a stemming algorithm that runs fast and does a reasonable job.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 69.


- fields:
    Front: |
      ## 08.06: Distributed throttling

      Let's say you have \\(N\\) machines crawling the world wide web such that the responsibility for a given URL is assigned to the crawler with id equal to `Hash(URL)`\\(\mod N\\). Downloading a page takes away bandwidth from the server hosting it. Therefore you want to ensure that in any given minute, your crawlers never request more than \\(B\\) bytes from any host.

      How would you implement crawling under such a constraint?

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 69.


- fields:
    Front: |
      ## 08.07: Implement PageRank

      The PageRank algorithm assigns ranks to web pages based on, for each page, the number of important links to this page. The algorithm essentially amounts to the following:

      1. Build a matrix \\(A\\) based on the hyperlink structure of the web, with \\(A_{ij} = \frac{1}{d_i}\\) if there is a link for webpage \\(i\\) to webpage \\(j\\), and \\(d_i\\) is the total number of unique outgoing links from page \\(i\\).

      2. Solve for \\(X\\) satisfying

          \\[
          X = \epsilon \cdot [1] + (1-\epsilon)A^T \cdot X.
          \\]

          Here \\(\epsilon\\) is a scalar constant (e.g., \\(\frac{1}{7}\\)), and \\([1]\\) represents a column vector of ones. The value \\(X[i]\\) is the rank of the \\(i\\)-th page.

      The most commonly used approach to solving the above equation is to start with a value of \\(X\\), where each component is \\(\frac{1}{n}\\) (where \\(n\\) is the number of pages), and then perform the following iteration:

      \\[
      X_k = \epsilon\cdot[1] + (1-\epsilon)A^T\cdot X_{k-1}.
      \\]

      How would you design a system that can compute the ranks for a collection of a billion web pages in a reasonable amount of time?

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 69-70.


- fields:
    Front: |
      ## 08.08: Scalable priority system

      Maintaining priority in a distributed system can be tricky --- consider the crawlers for a search engine visiting web pages in some prioritized order, or event-driven simulation in molecular dynamics. In both cases, we could be dealing with billions of entities with a given priority, and we need to do three things efficiently:

      1. find the highest priority entity,
      2. insert new entities with a given priority, and
      3. delete certain entities specified by a unique id.

      How would you design a system that can implement these requirements when the data cannot fit into a single machine's memory?

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 69-70.


- fields:
    Front: |
      ## 08.09: Latency reduction

      The Pareto distribution is defined as follows:

      \\[
      \begin{array}
      P[X>x] & = 1 - \left(\frac{x_m}{x}\right)^\alpha, \textrm{ if }x>x_m \\\\
      & = 1, \textrm{ if }x\le x_m
      \end{array}
      \\]

      Here \\(\alpha\\) and \\(x_m\\) are parameters of the distribution. It is one of the heavy-tailed distributions that commonly occur in various workloads.

      Suppose you are running a service on \\(k\\) servers, and that any service request can be processed by any of the servers. A given server can process only one request at a time. Depending on the request \\(r\\), a server may take time \\(t(r)\\), where \\(t(r)\\) follows a Pareto distribution.

      You have a service level agreement with your clients that requires that 99% of the requests are serviced in less that one second. How would you design the system to meet this requirement with minimal cost?

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 70.


- fields:
    Front: |
      ## 08.10: Online advertising system

      Jingle, a search engine startup, wants to monetize its search results by displaying advertisements alongside search results.

      Design an online advertising system for Jingle.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 70.


- fields:
    Front: |
      ## 08.11: Recommendation system

      Jingle wants to generate more page views on its news site. One idea the product manager has is to put in a sidebar of clickable snippets from articles that are likely to be of interest to the reader.

      Design a system that automatically generates the sidebar.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 71.


- fields:
    Front: |
      ## 08.12: Online poker

      Clump Enterprises has a large number of casinos. Their CEO wants to create a website by which gamblers can play poker online.

      Design an online poker playing service for Clump Enterprises.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 71.


- fields:
    Front: |
      ## 08.13: Driving directions

      As a part of their charter to collect all the information in the world and make it universally accessible, Jingle wants to develop a driving directions service. Users enter a start and finish address; the driving directions service returns directions.

      Design a driving directions service with a web interface.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 71.


- fields:
    Front: |
      ## 08.14: ISBN cache

      The International Standard Book Number (ISBN) is a unique commercial book identifier based on the 9-digit standard book numbering code developed by Professor Gordon Foster from Trinity University, Dublin. The ten-digit ISBN was ratified by the ISO in 1974; since 2007, ISBNs have contained 13 digits. The last digit in a ten-digit ISBN is the check digit --- it is the sum of the first 9 digits, modulo 11; a 10 is represented by an X. For 13-digit ISBNs, the last digit is also a check digit but is guaranteed to be between 0 and 9.

      Implement a cache for looking up prices of books identified by their ISBN. Use the least-recently-used strategy for cache eviction policy.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 71.


- fields:
    Front: |
      ## 08.15: Distributing large files

      Jingle is developing a search feature for breaking news. New articles are collected from a variety of online news sources such as newspapers, bulletin boards, blogs, etc. by a single lab machine at Jingle. Every minute,
      roughly one thousand articles are posted, and each article is about 100 kilobytes in size.

      Jingle would like to serve these articles from a datacenter consisting of a thousand servers. For performance reasons, each server should have a copy of articles that were recently added. The datacenter is far away from the lab machine.

      Suggest an efficient way of getting the articles added in the past five minutes from the lab machine to the servers.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 71-2.


- fields:
    Front: |
      ## 08.16: Leader election

      You are to devise a protocol by which a collection of hosts on the Internet can elect a leader. Hosts can communicate with each other using TCP connections. For host \\(A\\) to communicate with host \\(B\\), it needs to know \\(B\\)'s IP address. Each host starts off with a set of IP addresses and the protocol code that you implement that will run on a fixed port across all the hosts.

      Devise a protocol by which hosts can elect a unique leader from all the hosts participating in the protocol. The protocol should be fast, in that it converges quickly; it should be efficient, in that it should not involve too many connections, too many data exchanges, or too much data exchanged.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 72.


- fields:
    Front: |
      ## 08.17: Host discovery

      You are to devise a protocol by which a collection of hosts on the Internet can discover each other. Hosts can communicate with each other using TCP connections. For host \\(A\\) to communicate with host \\(B\\), it needs to know \\(B\\)'s IP address.

      Each host starts off with a set of IP addresses and the protocol code that you implement that will run on a fixed port across all the hosts.

      Devise a protocol by which hosts can discover all the hosts participating in the protocol.
      The protocol should be fast; it should be efficient, in that it should not involve too many connections, too many data exchanges, or too much data exchanged.

      --- Aziz and Prakash; _Algorithms for Interviews_; version 1.0.0 (September 1, 2010); p 72.
